{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "import sys\n",
    "[sys.path.append(i) for i in ['.', '..', '../ubisoft-laforge-ZeroEGGS/ZEGGS']]\n",
    "\n",
    "from anim import bvh, quat, txform\n",
    "\n",
    "# from process_zeggs_bvh import preprocess_animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.rand(1000, 50)\n",
    "labels = np.random.randint(0, 10, size=(1000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('dataset.h5', 'w') as hdf:\n",
    "    # Create datasets\n",
    "    hdf.create_dataset('features', data=data)\n",
    "    hdf.create_dataset('labels', data=labels)\n",
    "    \n",
    "    # Add metadata (attributes) to the file\n",
    "    hdf.attrs['description'] = 'Sample dataset with random data'\n",
    "    hdf.attrs['version'] = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description: Sample dataset with random data, Version: 1.0\n",
      "Features shape: (1000, 50), Labels shape: (1000,)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('dataset.h5', 'r') as hdf:\n",
    "    # Access datasets\n",
    "    features = hdf['features'][:]\n",
    "    labels = hdf['labels'][:]\n",
    "    \n",
    "    # Access metadata\n",
    "    description = hdf.attrs['description']\n",
    "    version = hdf.attrs['version']\n",
    "    \n",
    "    print(f\"Description: {description}, Version: {version}\")\n",
    "    print(f\"Features shape: {features.shape}, Labels shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = '../ubisoft-laforge-ZeroEGGS/data/processed_v1/trimmed/'\n",
    "target = '../ubisoft-laforge-ZeroEGGS/data/processed_v1/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def load_bvh_file(filename, start=None, end=None, order=None):\n",
    "    \n",
    "    channelmap = {\n",
    "        'Xrotation' : 'x',\n",
    "        'Yrotation' : 'y',\n",
    "        'Zrotation' : 'z'   \n",
    "    }\n",
    "    \n",
    "    f = open(filename, \"r\")\n",
    "\n",
    "    i = 0\n",
    "    active = -1\n",
    "    end_site = False\n",
    "    state = 'definition'\n",
    "    \n",
    "    names   = []\n",
    "    offsets = np.empty(shape=[0, 3], dtype=np.float32)\n",
    "    parents = np.empty(shape=[0],    dtype=np.int32)\n",
    "    \n",
    "    for line in f:\n",
    "        \n",
    "        if state == 'definition':\n",
    "        \n",
    "            if \"HIERARCHY\" in line: continue\n",
    "            if \"MOTION\" in line: continue\n",
    "\n",
    "            rmatch = re.match(r\"ROOT (\\w+)\", line)\n",
    "            if rmatch:\n",
    "                names.append(rmatch.group(1))\n",
    "                offsets = np.append(offsets, np.array([[0,0,0]], dtype=np.float32), axis=0)\n",
    "                parents = np.append(parents, np.array([active], dtype=np.int32))\n",
    "                active  = parents.shape[0]-1\n",
    "                continue\n",
    "\n",
    "            if \"{\" in line: continue\n",
    "\n",
    "            if \"}\" in line:\n",
    "                if end_site: end_site = False\n",
    "                else: active = parents[active]\n",
    "                continue\n",
    "            \n",
    "            offmatch = re.match(r\"\\s*OFFSET\\s+([\\-\\d\\.e]+)\\s+([\\-\\d\\.e]+)\\s+([\\-\\d\\.e]+)\", line)\n",
    "            if offmatch:\n",
    "                if not end_site:\n",
    "                    offsets[active] = np.array(list(map(float, offmatch.groups())))\n",
    "                continue\n",
    "               \n",
    "            chanmatch = re.match(r\"\\s*CHANNELS\\s+(\\d+)\", line)\n",
    "            if chanmatch:\n",
    "                channels = int(chanmatch.group(1))\n",
    "                if order is None:\n",
    "                    channelis = 0 if channels == 3 else 3\n",
    "                    channelie = 3 if channels == 3 else 6\n",
    "                    parts = line.split()[2+channelis:2+channelie]\n",
    "                    if any([p not in channelmap for p in parts]):\n",
    "                        continue\n",
    "                    order = \"\".join([channelmap[p] for p in parts])\n",
    "                continue\n",
    "\n",
    "            jmatch = re.match(r\"\\s*JOINT\\s+(\\w+)\", line)\n",
    "            if jmatch:\n",
    "                names.append(jmatch.group(1))\n",
    "                offsets = np.append(offsets, np.array([[0,0,0]], dtype=np.float32), axis=0)\n",
    "                parents = np.append(parents, np.array([active], dtype=np.int32))\n",
    "                active  = (parents.shape[0]-1)\n",
    "                continue\n",
    "            \n",
    "            if \"End Site\" in line:\n",
    "                end_site = True\n",
    "                continue\n",
    "                  \n",
    "            fmatch = re.match(r\"\\s*Frames:\\s+(\\d+)\", line)\n",
    "            if fmatch:\n",
    "                if start and end:\n",
    "                    fnum = (end - start)-1\n",
    "                else:\n",
    "                    fnum = int(fmatch.group(1))\n",
    "                jnum = parents.shape[0]\n",
    "                positions = offsets[np.newaxis].repeat(fnum, axis=0)\n",
    "                rotations = np.zeros([fnum, jnum, 3], dtype=np.float32)\n",
    "                continue\n",
    "            \n",
    "            fmatch = re.match(r\"\\s*Frame Time:\\s+([\\d\\.]+)\", line)\n",
    "            if fmatch:\n",
    "                frametime = float(fmatch.group(1))\n",
    "                state = 'body'\n",
    "                continue\n",
    "            \n",
    "        elif state == 'body':\n",
    "            \n",
    "            if (start and end) and (i < start or i >= end-1):\n",
    "                i += 1\n",
    "                continue\n",
    "            \n",
    "            dmatch = line.strip().split()\n",
    "            if dmatch:\n",
    "                \n",
    "                fi = i - start if start else i\n",
    "                data_block = np.asarray(tuple(map(float, dmatch)))\n",
    "                N = parents.shape[0]\n",
    "                if   channels == 3:\n",
    "                    positions[fi,0] = data_block[0:3]\n",
    "                    rotations[fi,:] = data_block[3: ].reshape([N, 3])\n",
    "                elif channels == 6:\n",
    "                    data_block = data_block.reshape([N, 6])\n",
    "                    positions[fi,:] = data_block[:,0:3]\n",
    "                    rotations[fi,:] = data_block[:,3:6]\n",
    "                elif channels == 9:\n",
    "                    positions[fi,0] = data_block[0:3]\n",
    "                    data_block = data_block[3:].reshape([N-1, 9])\n",
    "                    rotations[fi,1:] = data_block[:,3:6]\n",
    "                    positions[fi,1:] = positions[fi,1:] + data_block[:,0:3] * data_block[:,6:9]\n",
    "                else:\n",
    "                    raise Exception(\"Too many channels! %i\" % channels)\n",
    "\n",
    "                i += 1\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            raise Exception()\n",
    "        \n",
    "    f.close()\n",
    "    \n",
    "    return {\n",
    "        'rotations': rotations,\n",
    "        'positions': positions,\n",
    "        'offsets': offsets,\n",
    "        'parents': parents,\n",
    "        'names': names,\n",
    "        'order': order,\n",
    "        'frametime': frametime\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_animation(animation_file, fps=60):\n",
    "    anim_data = load_bvh_file(animation_file)       #  'rotations' (8116, 75, 3), 'positions', 'offsets' (75, 3), 'parents', 'names' (75,), 'order' 'zyx', 'frametime' 0.016667\n",
    "    nframes = len(anim_data[\"rotations\"])\n",
    "\n",
    "    if fps != 60 :\n",
    "        rate = 60 // fps\n",
    "        anim_data[\"rotations\"] = anim_data[\"rotations\"][0:nframes:rate]\n",
    "        anim_data[\"positions\"] = anim_data[\"positions\"][0:nframes:rate]\n",
    "        dt = 1 / fps\n",
    "        nframes = anim_data[\"positions\"].shape[0]\n",
    "    else:\n",
    "        dt = anim_data[\"frametime\"]\n",
    "\n",
    "    njoints = len(anim_data[\"parents\"])\n",
    "\n",
    "    lrot = quat.unroll(quat.from_euler(np.radians(anim_data[\"rotations\"]), anim_data[\"order\"]))\n",
    "    lpos = anim_data[\"positions\"]\n",
    "    grot, gpos = quat.fk(lrot, lpos, anim_data[\"parents\"])\n",
    "    # Find root (Projected hips on the ground)\n",
    "    root_pos = gpos[:, anim_data[\"names\"].index(\"Spine2\")] * np.array([1, 0, 1])\n",
    "    # Root direction\n",
    "    root_fwd = quat.mul_vec(grot[:, anim_data[\"names\"].index(\"Hips\")], np.array([[0, 0, 1]]))\n",
    "    root_fwd[:, 1] = 0\n",
    "    root_fwd = root_fwd / np.sqrt(np.sum(root_fwd * root_fwd, axis=-1))[..., np.newaxis]\n",
    "    # Root rotation\n",
    "    root_rot = quat.normalize(\n",
    "        quat.between(np.array([[0, 0, 1]]).repeat(len(root_fwd), axis=0), root_fwd)\n",
    "    )\n",
    "\n",
    "    # Find look at direction\n",
    "    gaze_lookat = quat.mul_vec(grot[:, anim_data[\"names\"].index(\"Head\")], np.array([0, 0, 1]))\n",
    "    gaze_lookat[:, 1] = 0\n",
    "    gaze_lookat = gaze_lookat / np.sqrt(np.sum(np.square(gaze_lookat), axis=-1))[..., np.newaxis]\n",
    "    # Find gaze position\n",
    "    gaze_distance = 100  # Assume other actor is one meter away\n",
    "    gaze_pos_all = root_pos + gaze_distance * gaze_lookat\n",
    "    gaze_pos = np.median(gaze_pos_all, axis=0)\n",
    "    gaze_pos = gaze_pos[np.newaxis].repeat(nframes, axis=0)\n",
    "\n",
    "    # Visualize Gaze Pos\n",
    "    visualize_gaze = False\n",
    "    if visualize_gaze:\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        plt.scatter(gaze_pos_all[:, 0], gaze_pos_all[:, 2], s=0.1, marker=\".\")\n",
    "        plt.scatter(gaze_pos[0, 0], gaze_pos[0, 2])\n",
    "        plt.scatter(root_pos[:, 0], root_pos[:, 2], s=0.1, marker=\".\")\n",
    "        plt.quiver(root_pos[::60, 0], root_pos[::60, 2], root_fwd[::60, 0], root_fwd[::60, 2])\n",
    "        plt.gca().set_aspect(\"equal\")\n",
    "        plt.savefig('1.jpg')\n",
    "        plt.show()\n",
    "\n",
    "    # Compute local gaze dir\n",
    "    gaze_dir = gaze_pos - root_pos\n",
    "    # gaze_dir = gaze_dir / np.sqrt(np.sum(np.square(gaze_dir), axis=-1))[..., np.newaxis]\n",
    "    gaze_dir = quat.mul_vec(quat.inv(root_rot), gaze_dir)\n",
    "\n",
    "    # Make relative to root\n",
    "    lrot[:, 0] = quat.mul(quat.inv(root_rot), lrot[:, 0])\n",
    "    lpos[:, 0] = quat.mul_vec(quat.inv(root_rot), lpos[:, 0] - root_pos)\n",
    "\n",
    "    # Local velocities\n",
    "    lvel = np.zeros_like(lpos)\n",
    "    lvel[1:] = (lpos[1:] - lpos[:-1]) / dt\n",
    "    lvel[0] = lvel[1] - (lvel[3] - lvel[2])\n",
    "\n",
    "    lvrt = np.zeros_like(lpos)\n",
    "    lvrt[1:] = quat.to_helical(quat.abs(quat.mul(lrot[1:], quat.inv(lrot[:-1])))) / dt\n",
    "    lvrt[0] = lvrt[1] - (lvrt[3] - lvrt[2])\n",
    "\n",
    "    # Root velocities\n",
    "    root_vrt = np.zeros_like(root_pos)\n",
    "    root_vrt[1:] = quat.to_helical(quat.abs(quat.mul(root_rot[1:], quat.inv(root_rot[:-1])))) / dt\n",
    "    root_vrt[0] = root_vrt[1] - (root_vrt[3] - root_vrt[2])\n",
    "    root_vrt[1:] = quat.mul_vec(quat.inv(root_rot[:-1]), root_vrt[1:])\n",
    "    root_vrt[0] = quat.mul_vec(quat.inv(root_rot[0]), root_vrt[0])\n",
    "\n",
    "    root_vel = np.zeros_like(root_pos)\n",
    "    root_vel[1:] = (root_pos[1:] - root_pos[:-1]) / dt\n",
    "    root_vel[0] = root_vel[1] - (root_vel[3] - root_vel[2])\n",
    "    root_vel[1:] = quat.mul_vec(quat.inv(root_rot[:-1]), root_vel[1:])\n",
    "    root_vel[0] = quat.mul_vec(quat.inv(root_rot[0]), root_vel[0])\n",
    "\n",
    "    # Compute character space\n",
    "    crot, cpos, cvrt, cvel = quat.fk_vel(lrot, lpos, lvrt, lvel, anim_data[\"parents\"])\n",
    "\n",
    "    # Compute 2-axis transforms\n",
    "    ltxy = np.zeros(dtype=np.float32, shape=[len(lrot), njoints, 2, 3])\n",
    "    ltxy[..., 0, :] = quat.mul_vec(lrot, np.array([1.0, 0.0, 0.0]))\n",
    "    ltxy[..., 1, :] = quat.mul_vec(lrot, np.array([0.0, 1.0, 0.0]))\n",
    "\n",
    "    ctxy = np.zeros(dtype=np.float32, shape=[len(crot), njoints, 2, 3])\n",
    "    ctxy[..., 0, :] = quat.mul_vec(crot, np.array([1.0, 0.0, 0.0]))\n",
    "    ctxy[..., 1, :] = quat.mul_vec(crot, np.array([0.0, 1.0, 0.0]))\n",
    "\n",
    "    # return (\n",
    "    #     root_pos,\n",
    "    #     root_rot,\n",
    "    #     root_vel,\n",
    "    #     root_vrt,\n",
    "    #     lpos,\n",
    "    #     lrot,\n",
    "    #     ltxy,\n",
    "    #     lvel,\n",
    "    #     lvrt,\n",
    "    #     cpos,\n",
    "    #     crot,\n",
    "    #     ctxy,\n",
    "    #     cvel,\n",
    "    #     cvrt,\n",
    "    #     gaze_pos,\n",
    "    #     gaze_dir,\n",
    "    # ), anim_data[\"parents\"], dt, anim_data[\"order\"]\n",
    "\n",
    "    lpos = lpos.reshape(nframes, -1)\n",
    "    ltxy = ltxy.reshape(nframes, -1)\n",
    "    lvel = lvel.reshape(nframes, -1)\n",
    "    lvrt = lvrt.reshape(nframes, -1)\n",
    "\n",
    "    all_poses = np.concatenate((root_pos, root_rot, root_vel, root_vrt, lpos, ltxy, lvel, lvrt, gaze_dir), axis=1)\n",
    "\n",
    "    return all_poses, anim_data[\"parents\"], dt, anim_data[\"order\"], njoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "animation_file_path = \"/Users/thanh/OpenHuman/OHGesture/ubisoft-laforge-ZeroEGGS/data/processed_v1/trimmed/valid/005_Neutral_4_x_0_9.bvh\"\n",
    "\n",
    "all_poses, parents, dt, order, njoints = preprocess_animation(animation_file_path, fps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_zeggs_dataset(source_path, target):\n",
    "    if not os.path.exists(target):\n",
    "        os.mkdir(target)\n",
    "\n",
    "    def make_zeggs_subdataset(source_path, target, all_poses):\n",
    "        if not os.path.exists(target):\n",
    "            os.mkdir(target)\n",
    "        target_audio_path = os.path.join(target, 'normalize_audio')\n",
    "        target_audionpz_path = os.path.join(target, 'normalize_audio_npz')\n",
    "        target_gesture_path = os.path.join(target, 'gesture_npz')\n",
    "        target_mfcc_path = os.path.join(target, 'mfcc')\n",
    "        if not os.path.exists(target_audio_path):\n",
    "            os.mkdir(target_audio_path)\n",
    "        if not os.path.exists(target_mfcc_path):\n",
    "            os.mkdir(target_mfcc_path)\n",
    "        if not os.path.exists(target_audionpz_path):\n",
    "            os.mkdir(target_audionpz_path)\n",
    "        if not os.path.exists(target_gesture_path):\n",
    "            os.mkdir(target_gesture_path)\n",
    "        wav_files = sorted(glob.glob(source_path + \"/*.wav\"))\n",
    "        for _, wav_file in enumerate(wav_files):\n",
    "            name = os.path.split(wav_file)[1][:-4]\n",
    "            print(name)\n",
    "            # audio\n",
    "            print('normalize audio: ' + name + '.wav')\n",
    "            normalize_wav_path = os.path.join(target_audio_path, name + '.wav')\n",
    "            cmd = ['ffmpeg-normalize', wav_file, '-o', normalize_wav_path, '-ar', '16000']\n",
    "            subprocess.call(cmd)\n",
    "            print('extract MFCC...')\n",
    "            obj = MFCC(frate=20)\n",
    "            # wav, fs = librosa.load(normalize_wav_path, sr=16000)\n",
    "            wav, fs = sf.read(normalize_wav_path)\n",
    "            mfcc = obj.sig2s2mfc_energy(wav, None)\n",
    "            print(mfcc[:, :-2].shape)  # -1 -> -2      # (502, 13)\n",
    "            np.savez_compressed(os.path.join(target_mfcc_path, name + '.npz'), mfcc=mfcc[:, :-2])\n",
    "            np.savez_compressed(os.path.join(target_audionpz_path, name + '.npz'), wav=wav)\n",
    "            # bvh\n",
    "            print('extract gesture...')\n",
    "            bvh_file = os.path.join(source_path, name + '.bvh')\n",
    "            pose, parents, dt, order, njoints = preprocess_animation(bvh_file, fps=20)\n",
    "            print(pose.shape)\n",
    "            np.savez_compressed(os.path.join(target_gesture_path, name + '.npz'), gesture=pose)\n",
    "            all_poses.append(pose)\n",
    "\n",
    "        return all_poses\n",
    "\n",
    "    source_path_train = os.path.join(source_path, 'train')\n",
    "    target_train = os.path.join(target, 'train')\n",
    "    all_poses = []\n",
    "    all_poses = make_zeggs_subdataset(source_path_train, target_train, all_poses)\n",
    "    source_path_test = os.path.join(source_path, 'valid')\n",
    "    target_test = os.path.join(target, 'valid')\n",
    "    all_poses = make_zeggs_subdataset(source_path_test, target_test, all_poses)\n",
    "\n",
    "    all_poses = np.vstack(all_poses)\n",
    "    pose_mean = np.mean(all_poses, axis=0, dtype=np.float64)\n",
    "    pose_std = np.std(all_poses, axis=0, dtype=np.float64)\n",
    "    np.savez_compressed(os.path.join(target, 'mean.npz'), mean=pose_mean)\n",
    "    np.savez_compressed(os.path.join(target, 'std.npz'), std=pose_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmake_zeggs_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m, in \u001b[0;36mmake_zeggs_dataset\u001b[0;34m(source_path, target)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_zeggs_dataset\u001b[39m(source_path, target):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(target):\n\u001b[1;32m      3\u001b[0m         os\u001b[38;5;241m.\u001b[39mmkdir(target)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_zeggs_subdataset\u001b[39m(source_path, target, all_poses):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "make_zeggs_dataset(source_path, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepPhaseSubmission",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
