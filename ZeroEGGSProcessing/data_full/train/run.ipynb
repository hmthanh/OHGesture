{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 7,
   "source": [
    "import os\n",
    "import nltk\n",
    "from gensim.models import KeyedVectors\n",
    "import csv"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/thanh/OpenHuman/OHGesture/ZeroEGGSProcessing/data_full/train'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3,
   "source": "os.getcwd()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 24,
   "source": [
    "word2vec_model_path = \"../../fasttext/crawl-300d-2M.vec\"\n",
    "word2vec_model = KeyedVectors.load_word2vec_format(word2vec_model_path, binary=False)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 48,
   "source": "files = [file for file in sorted(os.listdir(\"./corpus\")) if file.endswith(\".lab\")]"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 49,
   "source": [
    "text = list()\n",
    "\n",
    "for file in files:\n",
    "    with open(f\"./corpus/{file}\", \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        text.append(lines[0])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 45,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 58,
   "source": [
    "for t in text:\n",
    "    idx = str(t).find(\"'s\")\n",
    "    if idx != -1:\n",
    "        print(f\"{idx} '{t}' found at indes.\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 16,
   "source": [
    "for text_line in text:\n",
    "    tokens = nltk.word_tokenize(text_line)\n",
    "\n",
    "    # Recheck tokens in word2vec model\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            word2vec_model.get_vector(token)\n",
    "        except KeyError:\n",
    "            print(f\"Token {token} not found in word2vec model\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbbIbbb\n",
      "aaaIaaa\n",
      "\n",
      "bbbYbbb\n",
      "aaaYaaa\n",
      "\n",
      "bbb0bbb\n",
      "aaa0aaa\n",
      "\n"
     ]
    }
   ],
   "execution_count": 32,
   "source": [
    "for text_line in text:\n",
    "    tokens = nltk.word_tokenize(text_line)\n",
    "    # token_fixed = []\n",
    "    # for token in tokens:\n",
    "    #     token_fixed.append(expand_contractions(token))\n",
    "        \n",
    "    # token_fixed = \" \".join(token_fixed)\n",
    "    print(f\"bbb{tokens}bbb\")\n",
    "    print(f\"aaa{tokens}aaa\", end=\"\\n\\n\")\n",
    "    \n",
    "    # for tfixed in token_fixed:\n",
    "    #     try:\n",
    "    #         word2vec_model.get_vector(tfixed)\n",
    "    #     except KeyError:\n",
    "    #         print(f\"Token {tfixed} not found in word2vec model\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 54,
   "source": "csv_files = [f for f in sorted(os.listdir(\"./aligned\")) if f.endswith(\".csv\")]"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token karenina not found in word2vec model 047_Distracted_2_x_1_0.csv\n"
     ]
    }
   ],
   "execution_count": 58,
   "source": [
    "words = []\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    # print(f\"Reading {csv_file}\")\n",
    "    with open(os.path.join(\"./aligned\", csv_file), encoding='utf-8') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        next(csv_reader)\n",
    "        \n",
    "        for line in csv_reader:\n",
    "            start, end, text, align_type, speaker = line\n",
    "            if align_type == \"words\":\n",
    "                # words.append(text)\n",
    "                try:\n",
    "                    word2vec_model.get_vector(text)\n",
    "                except KeyError:\n",
    "                    print(f\"Token {text} not found in word2vec model {csv_file}\")\n",
    "            # print(f\"{start} {end} {text} {type} {speaker}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token karenina not found in word2vec model\n"
     ]
    }
   ],
   "execution_count": 57,
   "source": [
    "for word in words:\n",
    "    try:\n",
    "        word2vec_model.get_vector(word[0])\n",
    "    except KeyError:\n",
    "        print(f\"Token {word[0]} not found in word2vec model\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 12,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 11,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 12,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15,
   "source": "model[\"hello\"].shape"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T05:38:55.940089Z",
     "start_time": "2024-11-29T05:38:55.937015Z"
    }
   },
   "cell_type": "code",
   "source": "model[\"karenina\"].shape",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepPhaseSubmission",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
